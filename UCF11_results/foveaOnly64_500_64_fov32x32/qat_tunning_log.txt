
=== Processing Fold 1 ===
Loading float32 model from: UCF11_results/foveaOnly64_500_64_fov32x32/checkpoints/fold_1_best_model.keras
Applying Quantization-Aware Training wrapper...
Loading validation data for fine-tuning from: UCF11_results/foveaOnly64_500_64_fov32x32/test_data/fold_1_test_data.npz
Fine-tuning the QAT model for 10 epochs...
Epoch 1/10
313/313 - 15s - loss: 1.7727 - accuracy: 0.3896 - 15s/epoch - 48ms/step
Epoch 2/10
313/313 - 3s - loss: 1.8050 - accuracy: 0.3908 - 3s/epoch - 10ms/step
Epoch 3/10
313/313 - 3s - loss: 1.8036 - accuracy: 0.3917 - 3s/epoch - 9ms/step
Epoch 4/10
313/313 - 3s - loss: 1.7973 - accuracy: 0.3923 - 3s/epoch - 11ms/step
Epoch 5/10
313/313 - 4s - loss: 1.7896 - accuracy: 0.3969 - 4s/epoch - 13ms/step
Epoch 6/10
313/313 - 4s - loss: 1.7897 - accuracy: 0.3996 - 4s/epoch - 11ms/step
Epoch 7/10
313/313 - 4s - loss: 1.7998 - accuracy: 0.3954 - 4s/epoch - 12ms/step
Epoch 8/10
313/313 - 3s - loss: 1.7864 - accuracy: 0.3991 - 3s/epoch - 11ms/step
Epoch 9/10
313/313 - 3s - loss: 1.7939 - accuracy: 0.3965 - 3s/epoch - 10ms/step
Epoch 10/10
313/313 - 3s - loss: 1.7933 - accuracy: 0.3986 - 3s/epoch - 10ms/step
Converting the fine-tuned QAT model to TFLite INT8...
INFO:tensorflow:Assets written to: /tmp/tmpf5g1leov/assets
/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(
✅ C array saved with variable: fold1_model in UCF11_results/foveaOnly64_500_64_fov32x32/c_arrays_qat/fold1_model_data.h
Successfully converted and saved TFLite model for Fold 1 to:
UCF11_results/foveaOnly64_500_64_fov32x32/quantized_models_qat/fold_1_qat_model.tflite
Model size reduced from 153.27 KB to 14.37 KB

=== Processing Fold 2 ===
Loading float32 model from: UCF11_results/foveaOnly64_500_64_fov32x32/checkpoints/fold_2_best_model.keras
Applying Quantization-Aware Training wrapper...
Loading validation data for fine-tuning from: UCF11_results/foveaOnly64_500_64_fov32x32/test_data/fold_2_test_data.npz
Fine-tuning the QAT model for 10 epochs...
Epoch 1/10
313/313 - 14s - loss: 1.8279 - accuracy: 0.3762 - 14s/epoch - 44ms/step
Epoch 2/10
313/313 - 3s - loss: 1.8158 - accuracy: 0.3750 - 3s/epoch - 9ms/step
Epoch 3/10
313/313 - 3s - loss: 1.7919 - accuracy: 0.3797 - 3s/epoch - 10ms/step
Epoch 4/10
313/313 - 3s - loss: 1.7796 - accuracy: 0.3895 - 3s/epoch - 9ms/step
Epoch 5/10
313/313 - 3s - loss: 1.7760 - accuracy: 0.3844 - 3s/epoch - 10ms/step
Epoch 6/10
313/313 - 3s - loss: 1.7779 - accuracy: 0.3872 - 3s/epoch - 9ms/step
Epoch 7/10
313/313 - 3s - loss: 1.7712 - accuracy: 0.3950 - 3s/epoch - 10ms/step
Epoch 8/10
313/313 - 3s - loss: 1.7642 - accuracy: 0.3960 - 3s/epoch - 10ms/step
Epoch 9/10
313/313 - 3s - loss: 1.7732 - accuracy: 0.3934 - 3s/epoch - 10ms/step
Epoch 10/10
313/313 - 3s - loss: 1.7852 - accuracy: 0.3887 - 3s/epoch - 10ms/step
Converting the fine-tuned QAT model to TFLite INT8...
INFO:tensorflow:Assets written to: /tmp/tmpaley2t7b/assets
/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(
✅ C array saved with variable: fold2_model in UCF11_results/foveaOnly64_500_64_fov32x32/c_arrays_qat/fold2_model_data.h
Successfully converted and saved TFLite model for Fold 2 to:
UCF11_results/foveaOnly64_500_64_fov32x32/quantized_models_qat/fold_2_qat_model.tflite
Model size reduced from 153.27 KB to 14.39 KB

=== Processing Fold 3 ===
Loading float32 model from: UCF11_results/foveaOnly64_500_64_fov32x32/checkpoints/fold_3_best_model.keras
Applying Quantization-Aware Training wrapper...
Loading validation data for fine-tuning from: UCF11_results/foveaOnly64_500_64_fov32x32/test_data/fold_3_test_data.npz
Fine-tuning the QAT model for 10 epochs...
Epoch 1/10
313/313 - 17s - loss: 1.8024 - accuracy: 0.3717 - 17s/epoch - 55ms/step
Epoch 2/10
313/313 - 6s - loss: 1.8140 - accuracy: 0.3788 - 6s/epoch - 18ms/step
Epoch 3/10
313/313 - 4s - loss: 1.7967 - accuracy: 0.3831 - 4s/epoch - 14ms/step
Epoch 4/10
313/313 - 5s - loss: 1.7907 - accuracy: 0.3847 - 5s/epoch - 17ms/step
Epoch 5/10
313/313 - 5s - loss: 1.7868 - accuracy: 0.3817 - 5s/epoch - 15ms/step
Epoch 6/10
313/313 - 5s - loss: 1.7884 - accuracy: 0.3891 - 5s/epoch - 15ms/step
Epoch 7/10
313/313 - 5s - loss: 1.7928 - accuracy: 0.3832 - 5s/epoch - 17ms/step
Epoch 8/10
313/313 - 4s - loss: 1.8065 - accuracy: 0.3810 - 4s/epoch - 13ms/step
Epoch 9/10
313/313 - 4s - loss: 1.7857 - accuracy: 0.3862 - 4s/epoch - 14ms/step
Epoch 10/10
313/313 - 5s - loss: 1.7807 - accuracy: 0.3852 - 5s/epoch - 15ms/step
Converting the fine-tuned QAT model to TFLite INT8...
INFO:tensorflow:Assets written to: /tmp/tmp_x08ujlf/assets
/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(
✅ C array saved with variable: fold3_model in UCF11_results/foveaOnly64_500_64_fov32x32/c_arrays_qat/fold3_model_data.h
Successfully converted and saved TFLite model for Fold 3 to:
UCF11_results/foveaOnly64_500_64_fov32x32/quantized_models_qat/fold_3_qat_model.tflite
Model size reduced from 153.24 KB to 14.39 KB

=== Processing Fold 4 ===
Loading float32 model from: UCF11_results/foveaOnly64_500_64_fov32x32/checkpoints/fold_4_best_model.keras
Applying Quantization-Aware Training wrapper...
Loading validation data for fine-tuning from: UCF11_results/foveaOnly64_500_64_fov32x32/test_data/fold_4_test_data.npz
Fine-tuning the QAT model for 10 epochs...
Epoch 1/10
313/313 - 11s - loss: 1.8170 - accuracy: 0.3742 - 11s/epoch - 34ms/step
Epoch 2/10
313/313 - 1s - loss: 1.8035 - accuracy: 0.3797 - 1s/epoch - 5ms/step
Epoch 3/10
313/313 - 1s - loss: 1.8006 - accuracy: 0.3825 - 1s/epoch - 4ms/step
Epoch 4/10
313/313 - 1s - loss: 1.7922 - accuracy: 0.3852 - 1s/epoch - 4ms/step
Epoch 5/10
313/313 - 1s - loss: 1.7859 - accuracy: 0.3831 - 1s/epoch - 4ms/step
Epoch 6/10
313/313 - 1s - loss: 1.7813 - accuracy: 0.3858 - 1s/epoch - 4ms/step
Epoch 7/10
313/313 - 1s - loss: 1.7895 - accuracy: 0.3871 - 1s/epoch - 4ms/step
Epoch 8/10
313/313 - 1s - loss: 1.7836 - accuracy: 0.3896 - 1s/epoch - 4ms/step
Epoch 9/10
313/313 - 1s - loss: 1.7883 - accuracy: 0.3875 - 1s/epoch - 4ms/step
Epoch 10/10
313/313 - 1s - loss: 1.7883 - accuracy: 0.3890 - 1s/epoch - 5ms/step
Converting the fine-tuned QAT model to TFLite INT8...
INFO:tensorflow:Assets written to: /tmp/tmpyan0ylch/assets
/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(
✅ C array saved with variable: fold4_model in UCF11_results/foveaOnly64_500_64_fov32x32/c_arrays_qat/fold4_model_data.h
Successfully converted and saved TFLite model for Fold 4 to:
UCF11_results/foveaOnly64_500_64_fov32x32/quantized_models_qat/fold_4_qat_model.tflite
Model size reduced from 153.27 KB to 14.41 KB

=== Processing Fold 5 ===
Loading float32 model from: UCF11_results/foveaOnly64_500_64_fov32x32/checkpoints/fold_5_best_model.keras
Applying Quantization-Aware Training wrapper...
Loading validation data for fine-tuning from: UCF11_results/foveaOnly64_500_64_fov32x32/test_data/fold_5_test_data.npz
Fine-tuning the QAT model for 10 epochs...
Epoch 1/10
313/313 - 8s - loss: 1.7869 - accuracy: 0.3834 - 8s/epoch - 26ms/step
Epoch 2/10
313/313 - 2s - loss: 1.7936 - accuracy: 0.3839 - 2s/epoch - 5ms/step
Epoch 3/10
313/313 - 1s - loss: 1.7817 - accuracy: 0.3842 - 1s/epoch - 5ms/step
Epoch 4/10
313/313 - 2s - loss: 1.7860 - accuracy: 0.3870 - 2s/epoch - 7ms/step
Epoch 5/10
313/313 - 6s - loss: 1.7739 - accuracy: 0.3944 - 6s/epoch - 18ms/step
Epoch 6/10
313/313 - 5s - loss: 1.7637 - accuracy: 0.3939 - 5s/epoch - 17ms/step
Epoch 7/10
313/313 - 3s - loss: 1.7739 - accuracy: 0.3916 - 3s/epoch - 8ms/step
Epoch 8/10
313/313 - 1s - loss: 1.7679 - accuracy: 0.3965 - 1s/epoch - 4ms/step
Epoch 9/10
313/313 - 2s - loss: 1.7708 - accuracy: 0.3924 - 2s/epoch - 5ms/step
Epoch 10/10
313/313 - 2s - loss: 1.7705 - accuracy: 0.3904 - 2s/epoch - 7ms/step
Converting the fine-tuned QAT model to TFLite INT8...
INFO:tensorflow:Assets written to: /tmp/tmp_ugy7ldx/assets
/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(
✅ C array saved with variable: fold5_model in UCF11_results/foveaOnly64_500_64_fov32x32/c_arrays_qat/fold5_model_data.h
Successfully converted and saved TFLite model for Fold 5 to:
UCF11_results/foveaOnly64_500_64_fov32x32/quantized_models_qat/fold_5_qat_model.tflite
Model size reduced from 153.24 KB to 14.41 KB
