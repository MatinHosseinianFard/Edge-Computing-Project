{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:17:48.537851: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-10 22:17:48.537936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-10 22:17:48.540986: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-10 22:17:48.551426: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-10 22:17:50.942840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU detected and configured for training: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:17:54.470319: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-10 22:17:54.527800: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-10 22:17:54.528799: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import BackupAndRestore\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from typing import List, Dict\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(\"GPU detected and configured for training:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found. Training will run on CPU.\")\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "QAT_FINETUNE_EPOCHS = 10\n",
    "QAT_LEARNING_RATE = 1e-5\n",
    "\n",
    "MODEL_ARCH = \"32\"\n",
    "USE_CONTEXT = True\n",
    "USE_FOVEA = True\n",
    "\n",
    "DATASET = \"KTH\"\n",
    "EXPERIMENT = \"both32_500_64_ctx32x32_fov16x16\"\n",
    "\n",
    "CONTEXT_SHAPE = (32, 32, 1)\n",
    "FOVEA_SHAPE = (16, 16, 1)\n",
    "\n",
    "SHUFFLE_BUFFER = 30000\n",
    "CACHE_TO_DISK = True\n",
    "PREFETCH_TO_DEVICE = True\n",
    "\n",
    "\n",
    "OUTPUT_DIR = f\"{DATASET}_results/{EXPERIMENT}\"\n",
    "\n",
    "CLASS_NAMES = [\"basketball\",\"biking\",\"diving\",\n",
    "               \"golf_swing\",\"horse_riding\",\n",
    "               \"soccer_juggling\",\"swing\",\n",
    "               \"tennis_swing\",\"trampoline_jumping\",\n",
    "               \"volleyball_spiking\",\"walking\"] if DATASET == \"UCF11\" else [\"boxing\", \"handclapping\", \"handwaving\", \"walking\"]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "if not (USE_CONTEXT or USE_FOVEA):\n",
    "    raise ValueError(\"At least one of USE_CONTEXT or USE_FOVEA must be True.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef881dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_DIR = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
    "TEST_DATA_DIR = os.path.join(OUTPUT_DIR, \"test_data\")\n",
    "TFLITE_DIR = os.path.join(OUTPUT_DIR, \"quantized_models_qat\")\n",
    "os.makedirs(TFLITE_DIR, exist_ok=True)\n",
    "PIPE_CACHE_DIR = os.path.join(OUTPUT_DIR, \"pipeline_qat\")\n",
    "os.makedirs(PIPE_CACHE_DIR, exist_ok=True)\n",
    "C_ARRAY_DIR = os.path.join(OUTPUT_DIR, \"c_arrays_qat\")\n",
    "os.makedirs(C_ARRAY_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c28f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_ARCH == \"64\":\n",
    "    CHANNEL1_SIZE = 16\n",
    "    CHANNEL2_SIZE = 16\n",
    "    DENSE1_SIZE = 10\n",
    "    DENSE2_SIZE = 16\n",
    "elif MODEL_ARCH == \"32\":\n",
    "    CHANNEL1_SIZE = 16\n",
    "    CHANNEL2_SIZE = 32\n",
    "    DENSE1_SIZE = 20\n",
    "    DENSE2_SIZE = 32\n",
    "elif MODEL_ARCH == \"main\":\n",
    "    CHANNEL1_SIZE = 8\n",
    "    CHANNEL2_SIZE = 16\n",
    "    DENSE1_SIZE = 8\n",
    "    DENSE2_SIZE = 8\n",
    "\n",
    "def build_branch(input_shape, name_prefix=\"\"):\n",
    "    inp = tf.keras.Input(shape=input_shape, name=f\"{name_prefix}input\")\n",
    "    x = tf.keras.layers.Conv2D(CHANNEL1_SIZE, kernel_size=(3, 3), kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(inp)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Conv2D(CHANNEL2_SIZE, kernel_size=(3, 3), kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    return inp, x\n",
    "\n",
    "def build_model(\n",
    "    use_context: bool,\n",
    "    use_fovea: bool,\n",
    "    context_input_shape=CONTEXT_SHAPE,\n",
    "    fovea_input_shape=FOVEA_SHAPE,\n",
    "    num_classes=NUM_CLASSES\n",
    "):\n",
    "    inputs = []\n",
    "    branches = []\n",
    "    if use_context:\n",
    "        ctx_inp, ctx_out = build_branch(context_input_shape, name_prefix=\"context_\")\n",
    "        inputs.append(ctx_inp)\n",
    "        branches.append(ctx_out)\n",
    "    if use_fovea:\n",
    "        fov_inp, fov_out = build_branch(fovea_input_shape, name_prefix=\"fovea_\")\n",
    "        inputs.append(fov_inp)\n",
    "        branches.append(fov_out)\n",
    "    if len(branches) == 1:\n",
    "        fused = branches[0]\n",
    "        model_name = \"SingleStream_Context\" if use_context and not use_fovea else \"SingleStream_Fovea\"\n",
    "    else:\n",
    "        fused = tf.keras.layers.Concatenate()(branches)\n",
    "        model_name = \"MultiResFusion\"\n",
    "    z = tf.keras.layers.Dense(DENSE1_SIZE, kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(fused)\n",
    "    z = tf.keras.layers.Dropout(0.5)(z)\n",
    "    z = tf.keras.layers.Dense(DENSE2_SIZE, kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(z)\n",
    "    z = tf.keras.layers.Dropout(0.5)(z)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation=\"softmax\", kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(z)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67534061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_dataset(features_paths: Dict[str, List[str]],\n",
    "                      labels: np.ndarray,\n",
    "                      batch_size: int,\n",
    "                      shuffle: bool,\n",
    "                      drop_remainder: bool,\n",
    "                      cache_file: str = None,\n",
    "                      prefetch_to_device: bool = PREFETCH_TO_DEVICE):\n",
    "    for k, v in features_paths.items():\n",
    "        assert len(v) == len(labels), f\"Length mismatch between {k} paths and labels.\"\n",
    "    feat_elems = {k: tf.constant(v) for k, v in features_paths.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((feat_elems, labels))\n",
    "    opts = tf.data.Options()\n",
    "    opts.experimental_deterministic = False\n",
    "    opts.experimental_slack = True\n",
    "    ds = ds.with_options(opts)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=min(SHUFFLE_BUFFER, len(labels)))\n",
    "    ctx_h, ctx_w, _ = CONTEXT_SHAPE\n",
    "    fov_h, fov_w, _ = FOVEA_SHAPE\n",
    "    def _loader(features, label):\n",
    "        out_feats = {}\n",
    "        if \"context_input\" in features:\n",
    "            ctx = tf.io.read_file(features[\"context_input\"])\n",
    "            ctx = tf.io.decode_png(ctx, channels=1)\n",
    "            ctx = tf.image.convert_image_dtype(ctx, tf.float32)\n",
    "            ctx = tf.image.resize(ctx, [ctx_h, ctx_w])\n",
    "            ctx = tf.ensure_shape(ctx, CONTEXT_SHAPE)\n",
    "            out_feats[\"context_input\"] = ctx\n",
    "        if \"fovea_input\" in features:\n",
    "            fov = tf.io.read_file(features[\"fovea_input\"])\n",
    "            fov = tf.io.decode_png(fov, channels=1)\n",
    "            fov = tf.image.convert_image_dtype(fov, tf.float32)\n",
    "            fov = tf.image.resize(fov, [fov_h, fov_w])\n",
    "            fov = tf.ensure_shape(fov, FOVEA_SHAPE)\n",
    "            out_feats[\"fovea_input\"] = fov\n",
    "        return out_feats, label\n",
    "    ds = ds.map(_loader, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    if CACHE_TO_DISK and cache_file is not None:\n",
    "        os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
    "        ds = ds.cache(cache_file)\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    if prefetch_to_device:\n",
    "        try:\n",
    "            if hasattr(tf.data, \"experimental\") and hasattr(tf.data.experimental, \"prefetch_to_device\"):\n",
    "                ds = ds.apply(tf.data.experimental.prefetch_to_device(\"/GPU:0\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39495d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing Fold 1 ===\n",
      "Loading float32 model from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/checkpoints/fold_1_best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:17:54.644740: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-10 22:17:54.645798: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-10 22:17:54.646697: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-10 22:17:54.817891: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-10 22:17:54.819312: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-10 22:17:54.820286: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-08-10 22:17:54.821247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1109 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Quantization-Aware Training wrapper...\n",
      "Loading validation data for fine-tuning from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/test_data/fold_1_test_data.npz\n",
      "Fine-tuning the QAT model for 10 epochs...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:18:01.844556: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inMultiResFusion/quant_dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-08-10 22:18:02.100280: W tensorflow/core/grappler/optimizers/data/slack.cc:103] Could not find a final `prefetch` in the input pipeline to which to introduce slack.\n",
      "2025-08-10 22:18:02.843312: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-08-10 22:18:04.504626: I external/local_xla/xla/service/service.cc:168] XLA service 0x7b8626103ab0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-08-10 22:18:04.504757: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1650 Ti, Compute Capability 7.5\n",
      "2025-08-10 22:18:04.517030: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1754851684.713562  913135 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-08-10 22:18:44.668033: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 - 45s - loss: 0.2119 - accuracy: 0.9124 - 45s/epoch - 70ms/step\n",
      "Epoch 2/10\n",
      "645/645 - 8s - loss: 0.1500 - accuracy: 0.9525 - 8s/epoch - 12ms/step\n",
      "Epoch 3/10\n",
      "645/645 - 7s - loss: 0.1242 - accuracy: 0.9604 - 7s/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "645/645 - 6s - loss: 0.1234 - accuracy: 0.9622 - 6s/epoch - 10ms/step\n",
      "Epoch 5/10\n",
      "645/645 - 8s - loss: 0.1151 - accuracy: 0.9649 - 8s/epoch - 13ms/step\n",
      "Epoch 6/10\n",
      "645/645 - 6s - loss: 0.1172 - accuracy: 0.9646 - 6s/epoch - 9ms/step\n",
      "Epoch 7/10\n",
      "645/645 - 6s - loss: 0.1128 - accuracy: 0.9654 - 6s/epoch - 9ms/step\n",
      "Epoch 8/10\n",
      "645/645 - 6s - loss: 0.1140 - accuracy: 0.9653 - 6s/epoch - 9ms/step\n",
      "Epoch 9/10\n",
      "645/645 - 7s - loss: 0.1131 - accuracy: 0.9657 - 7s/epoch - 10ms/step\n",
      "Epoch 10/10\n",
      "645/645 - 7s - loss: 0.1139 - accuracy: 0.9645 - 7s/epoch - 11ms/step\n",
      "Converting the fine-tuned QAT model to TFLite INT8...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprtob_me5/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/tmprtob_me5/assets\n",
      "/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:19:52.916796: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-08-10 22:19:52.916857: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-08-10 22:19:52.917495: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmprtob_me5\n",
      "2025-08-10 22:19:52.927617: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-08-10 22:19:52.927654: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmprtob_me5\n",
      "2025-08-10 22:19:52.948783: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2025-08-10 22:19:52.961483: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-08-10 22:19:53.207115: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmprtob_me5\n",
      "2025-08-10 22:19:53.288124: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 370631 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 2, Total Ops 39, % non-converted = 5.13 %\n",
      " * 2 ARITH ops\n",
      "\n",
      "- arith.constant:    2 occurrences  (i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 4)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 7, uq_32: 7)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "2025-08-10 22:19:53.632346: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C array saved with variable: fold1_model in KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/c_arrays_qat/fold1_model_data.h\n",
      "Successfully converted and saved TFLite model for Fold 1 to:\n",
      "KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/quantized_models_qat/fold_1_qat_model.tflite\n",
      "Model size reduced from 494.82 KB to 45.69 KB\n",
      "\n",
      "=== Processing Fold 2 ===\n",
      "Loading float32 model from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/checkpoints/fold_2_best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Quantization-Aware Training wrapper...\n",
      "Loading validation data for fine-tuning from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/test_data/fold_2_test_data.npz\n",
      "Fine-tuning the QAT model for 10 epochs...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:20:07.128182: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inMultiResFusion/quant_dropout_4/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-08-10 22:20:07.557520: W tensorflow/core/grappler/optimizers/data/slack.cc:103] Could not find a final `prefetch` in the input pipeline to which to introduce slack.\n",
      "2025-08-10 22:20:43.440560: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 - 39s - loss: 0.2469 - accuracy: 0.8973 - 39s/epoch - 61ms/step\n",
      "Epoch 2/10\n",
      "645/645 - 8s - loss: 0.1432 - accuracy: 0.9522 - 8s/epoch - 12ms/step\n",
      "Epoch 3/10\n",
      "645/645 - 7s - loss: 0.1183 - accuracy: 0.9613 - 7s/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "645/645 - 8s - loss: 0.1164 - accuracy: 0.9645 - 8s/epoch - 13ms/step\n",
      "Epoch 5/10\n",
      "645/645 - 7s - loss: 0.1045 - accuracy: 0.9668 - 7s/epoch - 11ms/step\n",
      "Epoch 6/10\n",
      "645/645 - 8s - loss: 0.1089 - accuracy: 0.9666 - 8s/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "645/645 - 8s - loss: 0.1072 - accuracy: 0.9663 - 8s/epoch - 12ms/step\n",
      "Epoch 8/10\n",
      "645/645 - 8s - loss: 0.1061 - accuracy: 0.9669 - 8s/epoch - 12ms/step\n",
      "Epoch 9/10\n",
      "645/645 - 7s - loss: 0.1075 - accuracy: 0.9665 - 7s/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "645/645 - 7s - loss: 0.1028 - accuracy: 0.9681 - 7s/epoch - 11ms/step\n",
      "Converting the fine-tuned QAT model to TFLite INT8...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpr_77ygyl/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpr_77ygyl/assets\n",
      "/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:21:58.970153: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-08-10 22:21:58.970185: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-08-10 22:21:58.970437: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpr_77ygyl\n",
      "2025-08-10 22:21:58.979158: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-08-10 22:21:58.979192: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpr_77ygyl\n",
      "2025-08-10 22:21:59.013018: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-08-10 22:21:59.250361: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpr_77ygyl\n",
      "2025-08-10 22:21:59.326233: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 355798 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 2, Total Ops 39, % non-converted = 5.13 %\n",
      " * 2 ARITH ops\n",
      "\n",
      "- arith.constant:    2 occurrences  (i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 4)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 7, uq_32: 7)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "2025-08-10 22:21:59.640964: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C array saved with variable: fold2_model in KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/c_arrays_qat/fold2_model_data.h\n",
      "Successfully converted and saved TFLite model for Fold 2 to:\n",
      "KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/quantized_models_qat/fold_2_qat_model.tflite\n",
      "Model size reduced from 494.78 KB to 45.73 KB\n",
      "\n",
      "=== Processing Fold 3 ===\n",
      "Loading float32 model from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/checkpoints/fold_3_best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Quantization-Aware Training wrapper...\n",
      "Loading validation data for fine-tuning from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/test_data/fold_3_test_data.npz\n",
      "Fine-tuning the QAT model for 10 epochs...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:22:13.530607: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inMultiResFusion/quant_dropout_8/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-08-10 22:22:13.923415: W tensorflow/core/grappler/optimizers/data/slack.cc:103] Could not find a final `prefetch` in the input pipeline to which to introduce slack.\n",
      "2025-08-10 22:22:46.928793: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 - 37s - loss: 0.2560 - accuracy: 0.8908 - 37s/epoch - 57ms/step\n",
      "Epoch 2/10\n",
      "645/645 - 7s - loss: 0.1434 - accuracy: 0.9516 - 7s/epoch - 11ms/step\n",
      "Epoch 3/10\n",
      "645/645 - 7s - loss: 0.1270 - accuracy: 0.9592 - 7s/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "645/645 - 7s - loss: 0.1169 - accuracy: 0.9637 - 7s/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "645/645 - 7s - loss: 0.1182 - accuracy: 0.9631 - 7s/epoch - 11ms/step\n",
      "Epoch 6/10\n",
      "645/645 - 7s - loss: 0.1080 - accuracy: 0.9656 - 7s/epoch - 11ms/step\n",
      "Epoch 7/10\n",
      "645/645 - 7s - loss: 0.1049 - accuracy: 0.9672 - 7s/epoch - 11ms/step\n",
      "Epoch 8/10\n",
      "645/645 - 7s - loss: 0.1087 - accuracy: 0.9662 - 7s/epoch - 11ms/step\n",
      "Epoch 9/10\n",
      "645/645 - 7s - loss: 0.1109 - accuracy: 0.9654 - 7s/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "645/645 - 7s - loss: 0.1106 - accuracy: 0.9659 - 7s/epoch - 11ms/step\n",
      "Converting the fine-tuned QAT model to TFLite INT8...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpop_bg1n4/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpop_bg1n4/assets\n",
      "/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:23:55.994438: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-08-10 22:23:55.994471: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-08-10 22:23:55.994721: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpop_bg1n4\n",
      "2025-08-10 22:23:56.004825: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-08-10 22:23:56.004864: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpop_bg1n4\n",
      "2025-08-10 22:23:56.038305: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-08-10 22:23:56.296421: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpop_bg1n4\n",
      "2025-08-10 22:23:56.395253: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 400532 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 2, Total Ops 39, % non-converted = 5.13 %\n",
      " * 2 ARITH ops\n",
      "\n",
      "- arith.constant:    2 occurrences  (i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 4)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 7, uq_32: 7)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "2025-08-10 22:23:56.735589: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C array saved with variable: fold3_model in KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/c_arrays_qat/fold3_model_data.h\n",
      "Successfully converted and saved TFLite model for Fold 3 to:\n",
      "KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/quantized_models_qat/fold_3_qat_model.tflite\n",
      "Model size reduced from 494.78 KB to 45.73 KB\n",
      "\n",
      "=== Processing Fold 4 ===\n",
      "Loading float32 model from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/checkpoints/fold_4_best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Quantization-Aware Training wrapper...\n",
      "Loading validation data for fine-tuning from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/test_data/fold_4_test_data.npz\n",
      "Fine-tuning the QAT model for 10 epochs...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:24:09.758205: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inMultiResFusion/quant_dropout_12/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-08-10 22:24:10.159509: W tensorflow/core/grappler/optimizers/data/slack.cc:103] Could not find a final `prefetch` in the input pipeline to which to introduce slack.\n",
      "2025-08-10 22:24:44.911301: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 - 38s - loss: 0.3037 - accuracy: 0.8788 - 38s/epoch - 59ms/step\n",
      "Epoch 2/10\n",
      "645/645 - 7s - loss: 0.1613 - accuracy: 0.9461 - 7s/epoch - 12ms/step\n",
      "Epoch 3/10\n",
      "645/645 - 7s - loss: 0.1377 - accuracy: 0.9583 - 7s/epoch - 12ms/step\n",
      "Epoch 4/10\n",
      "645/645 - 7s - loss: 0.1192 - accuracy: 0.9631 - 7s/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "645/645 - 8s - loss: 0.1178 - accuracy: 0.9647 - 8s/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "645/645 - 7s - loss: 0.1146 - accuracy: 0.9650 - 7s/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "645/645 - 7s - loss: 0.1139 - accuracy: 0.9665 - 7s/epoch - 11ms/step\n",
      "Epoch 8/10\n",
      "645/645 - 7s - loss: 0.1165 - accuracy: 0.9653 - 7s/epoch - 11ms/step\n",
      "Epoch 9/10\n",
      "645/645 - 7s - loss: 0.1124 - accuracy: 0.9651 - 7s/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "645/645 - 7s - loss: 0.1139 - accuracy: 0.9657 - 7s/epoch - 11ms/step\n",
      "Converting the fine-tuned QAT model to TFLite INT8...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdb3deu_r/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdb3deu_r/assets\n",
      "/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:25:59.259403: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-08-10 22:25:59.259440: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-08-10 22:25:59.259693: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpdb3deu_r\n",
      "2025-08-10 22:25:59.268977: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-08-10 22:25:59.269053: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmpdb3deu_r\n",
      "2025-08-10 22:25:59.299666: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-08-10 22:25:59.572290: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmpdb3deu_r\n",
      "2025-08-10 22:25:59.652899: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 393208 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 2, Total Ops 39, % non-converted = 5.13 %\n",
      " * 2 ARITH ops\n",
      "\n",
      "- arith.constant:    2 occurrences  (i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 4)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 7, uq_32: 7)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "2025-08-10 22:25:59.967858: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C array saved with variable: fold4_model in KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/c_arrays_qat/fold4_model_data.h\n",
      "Successfully converted and saved TFLite model for Fold 4 to:\n",
      "KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/quantized_models_qat/fold_4_qat_model.tflite\n",
      "Model size reduced from 494.82 KB to 45.74 KB\n",
      "\n",
      "=== Processing Fold 5 ===\n",
      "Loading float32 model from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/checkpoints/fold_5_best_model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Quantization-Aware Training wrapper...\n",
      "Loading validation data for fine-tuning from: KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/test_data/fold_5_test_data.npz\n",
      "Fine-tuning the QAT model for 10 epochs...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:26:13.464033: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inMultiResFusion/quant_dropout_16/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-08-10 22:26:13.788449: W tensorflow/core/grappler/optimizers/data/slack.cc:103] Could not find a final `prefetch` in the input pipeline to which to introduce slack.\n",
      "2025-08-10 22:26:47.876917: W tensorflow/core/kernels/data/cache_dataset_ops.cc:302] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 - 38s - loss: 0.2673 - accuracy: 0.8958 - 38s/epoch - 58ms/step\n",
      "Epoch 2/10\n",
      "645/645 - 7s - loss: 0.1567 - accuracy: 0.9493 - 7s/epoch - 11ms/step\n",
      "Epoch 3/10\n",
      "645/645 - 7s - loss: 0.1283 - accuracy: 0.9593 - 7s/epoch - 11ms/step\n",
      "Epoch 4/10\n",
      "645/645 - 7s - loss: 0.1260 - accuracy: 0.9610 - 7s/epoch - 11ms/step\n",
      "Epoch 5/10\n",
      "645/645 - 7s - loss: 0.1130 - accuracy: 0.9644 - 7s/epoch - 11ms/step\n",
      "Epoch 6/10\n",
      "645/645 - 8s - loss: 0.1185 - accuracy: 0.9644 - 8s/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "645/645 - 8s - loss: 0.1211 - accuracy: 0.9636 - 8s/epoch - 12ms/step\n",
      "Epoch 8/10\n",
      "645/645 - 7s - loss: 0.1127 - accuracy: 0.9661 - 7s/epoch - 12ms/step\n",
      "Epoch 9/10\n",
      "645/645 - 7s - loss: 0.1142 - accuracy: 0.9647 - 7s/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "645/645 - 7s - loss: 0.1142 - accuracy: 0.9653 - 7s/epoch - 12ms/step\n",
      "Converting the fine-tuned QAT model to TFLite INT8...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmps42vr_sd/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/tmps42vr_sd/assets\n",
      "/home/matin/uni/Term2/Edge/Replication/venv_for_qat/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-10 22:28:01.909814: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-08-10 22:28:01.909844: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2025-08-10 22:28:01.910088: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmps42vr_sd\n",
      "2025-08-10 22:28:01.916724: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2025-08-10 22:28:01.916764: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmps42vr_sd\n",
      "2025-08-10 22:28:01.943269: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2025-08-10 22:28:02.172079: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmps42vr_sd\n",
      "2025-08-10 22:28:02.259246: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 349156 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 2, Total Ops 39, % non-converted = 5.13 %\n",
      " * 2 ARITH ops\n",
      "\n",
      "- arith.constant:    2 occurrences  (i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 4)\n",
      "  (f32: 1)\n",
      "  (uq_8: 3)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 7, uq_32: 7)\n",
      "  (uq_8: 4)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "2025-08-10 22:28:02.564882: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ C array saved with variable: fold5_model in KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/c_arrays_qat/fold5_model_data.h\n",
      "Successfully converted and saved TFLite model for Fold 5 to:\n",
      "KTH_results/results_he_normal_zeros_both32_500_64_ctx32x32_fov16x16/quantized_models_qat/fold_5_qat_model.tflite\n",
      "Model size reduced from 494.78 KB to 45.74 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "class Tee(object):\n",
    "    def __init__(self, filename, mode=\"a\"):\n",
    "        self.file = open(filename, mode, encoding=\"utf-8\")\n",
    "        self.stdout = sys.stdout\n",
    "    def write(self, data):\n",
    "        self.file.write(data); self.file.flush()\n",
    "        self.stdout.write(data); self.stdout.flush()\n",
    "    def flush(self):\n",
    "        self.file.flush(); self.stdout.flush()\n",
    "\n",
    "tee = Tee(os.path.join(OUTPUT_DIR, \"qat_tunning_log.txt\"), \"a\")\n",
    "sys.stdout = tee\n",
    "sys.stderr = tee\n",
    "\n",
    "\n",
    "for fold_index in range(1, 6):\n",
    "    print(f\"\\n=== Processing Fold {fold_index} ===\")\n",
    "\n",
    "    keras_model_path = os.path.join(CHECKPOINTS_DIR, f\"fold_{fold_index}_best_model.keras\")\n",
    "    val_data_path = os.path.join(TEST_DATA_DIR, f\"fold_{fold_index}_test_data.npz\")\n",
    "    tflite_model_path = os.path.join(TFLITE_DIR, f\"fold_{fold_index}_qat_model.tflite\")\n",
    "    tmp_c_path = os.path.join(C_ARRAY_DIR, f\"_tmp_fold{fold_index}.h\")\n",
    "    final_c_path = os.path.join(C_ARRAY_DIR, f\"fold{fold_index}_model_data.h\")\n",
    "\n",
    "    if not os.path.exists(keras_model_path):\n",
    "        print(f\"Skipping Fold {fold_index}: Model file not found at {keras_model_path}\")\n",
    "        continue\n",
    "        \n",
    "    if not os.path.exists(val_data_path):\n",
    "        print(f\"Skipping Fold {fold_index}: Validation data not found at {val_data_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Loading float32 model from: {keras_model_path}\")\n",
    "    float_model = build_model(USE_CONTEXT, USE_FOVEA, CONTEXT_SHAPE, FOVEA_SHAPE, NUM_CLASSES)\n",
    "    float_model.load_weights(keras_model_path)\n",
    "    \n",
    "    print(\"Applying Quantization-Aware Training wrapper...\")\n",
    "    quant_aware_model = tfmot.quantization.keras.quantize_model(float_model)\n",
    "    \n",
    "    quant_aware_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=QAT_LEARNING_RATE),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Loading validation data for fine-tuning from: {val_data_path}\")\n",
    "    val_data = np.load(val_data_path, allow_pickle=True)\n",
    "    y_val_fold = val_data['y']\n",
    "    \n",
    "    features_val_fold = {}\n",
    "    if USE_CONTEXT:\n",
    "        features_val_fold[\"context_input\"] = val_data[\"X_context_paths\"].tolist()\n",
    "    if USE_FOVEA:\n",
    "        features_val_fold[\"fovea_input\"] = val_data[\"X_fovea_paths\"].tolist()\n",
    "\n",
    "    cache_file = os.path.join(PIPE_CACHE_DIR, f\"fold{fold_index}_val.cache\")\n",
    "    val_dataset = make_tf_dataset(\n",
    "        features_val_fold, y_val_fold,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        drop_remainder=True,\n",
    "        cache_file=cache_file\n",
    "    )\n",
    "\n",
    "    fold_best_checkpoint_path = os.path.join(TFLITE_DIR, f\"fold_{fold_index}_best_model.keras\")\n",
    "    fold_backup_dir = os.path.join(TFLITE_DIR, f\"fold_{fold_index}_backup\")\n",
    "\n",
    "\n",
    "    backup_and_restore_callback = BackupAndRestore(backup_dir=fold_backup_dir)\n",
    "    \n",
    "    print(f\"Fine-tuning the QAT model for {QAT_FINETUNE_EPOCHS} epochs...\")\n",
    "    quant_aware_model.fit(\n",
    "        val_dataset,\n",
    "        epochs=QAT_FINETUNE_EPOCHS,\n",
    "        verbose=2,\n",
    "        callbacks=[\n",
    "            backup_and_restore_callback,\n",
    "        ])\n",
    "    \n",
    "    print(\"Converting the fine-tuned QAT model to TFLite INT8...\")\n",
    "    \n",
    "    def representative_dataset_gen():\n",
    "        for features, _ in val_dataset.take(10000):\n",
    "            yield features\n",
    "\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset_gen\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.int8\n",
    "    converter.inference_output_type = tf.int8\n",
    "    \n",
    "    tflite_model_quant = converter.convert()\n",
    "    \n",
    "    with open(tflite_model_path, 'wb') as f:\n",
    "        f.write(tflite_model_quant)\n",
    "    \n",
    "    with open(tmp_c_path, \"w\") as out:\n",
    "        subprocess.run([\"xxd\", \"-i\", tflite_model_path], stdout=out)\n",
    "\n",
    "    with open(tmp_c_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    var_name = f\"fold{fold_index}_model\"\n",
    "\n",
    "    content = re.sub(r'unsigned char\\s+\\w+\\s*\\[\\]', f'unsigned char {var_name}[]', content)\n",
    "    content = re.sub(r'unsigned int\\s+\\w+_len', f'unsigned int {var_name}_len', content)\n",
    "\n",
    "    guard_name = f\"FOLD{fold_index}_MODEL_DATA_H\"\n",
    "    header_guard = f\"#ifndef {guard_name}\\n#define {guard_name}\\n\\n\"\n",
    "    footer_guard = \"\\n#endif\\n\"\n",
    "\n",
    "    with open(final_c_path, \"w\") as f:\n",
    "        f.write(header_guard)\n",
    "        f.write(content)\n",
    "        f.write(footer_guard)\n",
    "\n",
    "    os.remove(tmp_c_path)\n",
    "    print(f\"✅ C array saved with variable: {var_name} in {final_c_path}\")\n",
    "        \n",
    "    print(f\"Successfully converted and saved TFLite model for Fold {fold_index} to:\")\n",
    "    print(tflite_model_path)\n",
    "    \n",
    "    original_size = os.path.getsize(keras_model_path) / 1024\n",
    "    quantized_size = len(tflite_model_quant) / 1024\n",
    "    print(f\"Model size reduced from {original_size:.2f} KB to {quantized_size:.2f} KB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_for_qat (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
