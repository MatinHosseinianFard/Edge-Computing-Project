{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - Imports and hyperparameters\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import gc\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (confusion_matrix, classification_report,\n",
    "precision_score, recall_score, f1_score\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, BackupAndRestore\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "DATASET = \"KTH\"\n",
    "\n",
    "MODEL_ARCH = \"32\"\n",
    "USE_CONTEXT = True\n",
    "USE_FOVEA   = True\n",
    "PauseCounter = 500\n",
    "\n",
    "CONTEXT_SHAPE = (32, 32, 1)\n",
    "FOVEA_SHAPE   = (16, 16, 1)\n",
    "REVERSE_RESOLUTION = False\n",
    "\n",
    "ENABLE_XLA_JIT      = True\n",
    "CACHE_TO_DISK       = True\n",
    "PREFETCH_TO_DEVICE  = True\n",
    "SHUFFLE_BUFFER      = 30000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 - Configure TensorFlow JIT and GPU\n",
    "try:\n",
    "    tf.config.optimizer.set_jit(ENABLE_XLA_JIT)\n",
    "    print(\"XLA JIT:\", \"ENABLED\" if ENABLE_XLA_JIT else \"DISABLED\")\n",
    "except Exception as e:\n",
    "    print(\"Could not set XLA JIT:\", e)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        print(\"GPU detected and configured for training:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPU found. Training will run on CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 - Resolve streams, paths, classes, resolutions\n",
    "BOTH_STREAMS = USE_CONTEXT and USE_FOVEA\n",
    "if not (USE_CONTEXT or USE_FOVEA):\n",
    "    raise ValueError(\"At least one of USE_CONTEXT or USE_FOVEA must be True.\")\n",
    "\n",
    "PREPROCESSED_DIR = f\"/mnt/60FE87C2FE878F4A/Uni/Master's/Term2/Edge/Replication/datasets/{DATASET}/preprocessed_frames\"\n",
    "\n",
    "CLASS_NAMES = [\"basketball\",\"biking\",\"diving\",\n",
    "               \"golf_swing\",\"horse_riding\",\n",
    "               \"soccer_juggling\",\"swing\",\n",
    "               \"tennis_swing\",\"trampoline_jumping\",\n",
    "               \"volleyball_spiking\",\"walking\"] if DATASET == \"UCF11\" else [\"boxing\", \"handclapping\", \"handwaving\", \"walking\"]\n",
    "\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "context_res = f\"{CONTEXT_SHAPE[0]}x{CONTEXT_SHAPE[1]}\"\n",
    "fovea_res   = f\"{FOVEA_SHAPE[0]}x{FOVEA_SHAPE[1]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4 - Define model architecture and build\n",
    "if MODEL_ARCH == \"64\":\n",
    "    CHANNEL1_SIZE = 16\n",
    "    CHANNEL2_SIZE = 16\n",
    "    DENSE1_SIZE = 10\n",
    "    DENSE2_SIZE = 16\n",
    "elif MODEL_ARCH == \"32\":\n",
    "    CHANNEL1_SIZE = 16\n",
    "    CHANNEL2_SIZE = 32\n",
    "    DENSE1_SIZE = 20\n",
    "    DENSE2_SIZE = 32\n",
    "elif MODEL_ARCH == \"main\":\n",
    "    CHANNEL1_SIZE = 8\n",
    "    CHANNEL2_SIZE = 16\n",
    "    DENSE1_SIZE = 8\n",
    "    DENSE2_SIZE = 8\n",
    "\n",
    "def build_branch(input_shape, name_prefix=\"\"):\n",
    "    inp = keras.Input(shape=input_shape, name=f\"{name_prefix}input\")\n",
    "    x = layers.Conv2D(CHANNEL1_SIZE, kernel_size=(3, 3),\n",
    "                      kernel_initializer=\"he_normal\",\n",
    "                      bias_initializer=\"zeros\")(inp)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(CHANNEL2_SIZE, kernel_size=(3, 3),\n",
    "                      kernel_initializer=\"he_normal\",\n",
    "                      bias_initializer=\"zeros\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    return inp, x\n",
    "\n",
    "def build_model(\n",
    "    use_context: bool,\n",
    "    use_fovea: bool,\n",
    "    context_input_shape=CONTEXT_SHAPE,\n",
    "    fovea_input_shape=FOVEA_SHAPE,\n",
    "    num_classes=NUM_CLASSES\n",
    "):\n",
    "    inputs = []\n",
    "    branches = []\n",
    "    if use_context:\n",
    "        ctx_inp, ctx_out = build_branch(context_input_shape, name_prefix=\"context_\")\n",
    "        inputs.append(ctx_inp)\n",
    "        branches.append(ctx_out)\n",
    "    if use_fovea:\n",
    "        fov_inp, fov_out = build_branch(fovea_input_shape, name_prefix=\"fovea_\")\n",
    "        inputs.append(fov_inp)\n",
    "        branches.append(fov_out)\n",
    "    if len(branches) == 1:\n",
    "        fused = branches[0]\n",
    "        model_name = \"SingleStream_Context\" if use_context and not use_fovea else \"SingleStream_Fovea\"\n",
    "    else:\n",
    "        fused = layers.Concatenate()(branches)\n",
    "        model_name = \"MultiResFusion\"\n",
    "    z = layers.Dense(DENSE1_SIZE, kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(fused)\n",
    "    z = layers.Dropout(0.5)(z)\n",
    "    z = layers.Dense(DENSE2_SIZE, kernel_initializer=\"he_normal\", bias_initializer=\"zeros\")(z)\n",
    "    z = layers.Dropout(0.5)(z)\n",
    "    output = layers.Dense(num_classes, activation=\"softmax\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          bias_initializer=\"zeros\")(z)\n",
    "    model = Model(inputs=inputs, outputs=output, name=model_name)\n",
    "    return model\n",
    "\n",
    "model = build_model(USE_CONTEXT, USE_FOVEA, CONTEXT_SHAPE, FOVEA_SHAPE, NUM_CLASSES)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 - Prepare output directories and paths\n",
    "mode_tag = f\"reverseResolution{MODEL_ARCH}\" if REVERSE_RESOLUTION else f\"both{MODEL_ARCH}\" if (USE_CONTEXT and USE_FOVEA) else f\"contextOnly{MODEL_ARCH}\" if USE_CONTEXT else f\"foveaOnly{MODEL_ARCH}\" if USE_FOVEA else \"invalid\"\n",
    "OUTPUT_DIR = f\"{DATASET}_results/{mode_tag}_{EPOCHS}_{BATCH_SIZE}\" \\\n",
    "             f\"{'_ctx' + str(CONTEXT_SHAPE[0]) + 'x' + str(CONTEXT_SHAPE[1]) if USE_CONTEXT else ''}\" \\\n",
    "             f\"{'_fov' + str(FOVEA_SHAPE[0]) + 'x' + str(FOVEA_SHAPE[1]) if USE_FOVEA else ''}\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CHECKPOINTS_DIR = os.path.join(OUTPUT_DIR, \"checkpoints\"); os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "PLOTS_DIR       = os.path.join(OUTPUT_DIR, \"plots\");       os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "TEST_DATA_DIR   = os.path.join(OUTPUT_DIR, \"test_data\");   os.makedirs(TEST_DATA_DIR, exist_ok=True)\n",
    "LOG_PATH        = os.path.join(OUTPUT_DIR, \"training_metrics.csv\")\n",
    "PIPE_CACHE_DIR  = os.path.join(OUTPUT_DIR, \"pipeline\");     os.makedirs(PIPE_CACHE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 - tf.data utilities for loading images\n",
    "def list_images_for_stream(split: str, resolution: str, class_names: List[str]) -> Tuple[List[str], np.ndarray, List[str]]:\n",
    "    paths, labels, filenames = [], [], []\n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(PREPROCESSED_DIR, split, resolution, class_name)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            print(\"XXXX - Directory not found:\", class_dir)\n",
    "            continue\n",
    "        for fname in sorted(os.listdir(class_dir)):\n",
    "            if fname.lower().endswith('.png'):\n",
    "                paths.append(os.path.join(class_dir, fname))\n",
    "                labels.append(class_idx)\n",
    "                filenames.append(fname)\n",
    "    labels = np.array(labels, dtype=np.int32)\n",
    "    return paths, labels, filenames\n",
    "\n",
    "def make_tf_dataset(features_paths: Dict[str, List[str]],\n",
    "                    labels: np.ndarray,\n",
    "                    batch_size: int,\n",
    "                    shuffle: bool,\n",
    "                    drop_remainder: bool,\n",
    "                    cache_file: str = None,\n",
    "                    prefetch_to_device: bool = PREFETCH_TO_DEVICE):\n",
    "    for k, v in features_paths.items():\n",
    "        assert len(v) == len(labels), f\"Length mismatch between {k} paths and labels.\"\n",
    "    feat_elems = {k: tf.constant(v) for k, v in features_paths.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((feat_elems, labels))\n",
    "    opts = tf.data.Options()\n",
    "    opts.experimental_deterministic = False\n",
    "    opts.experimental_slack = True\n",
    "    ds = ds.with_options(opts)\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=min(SHUFFLE_BUFFER, len(labels)))\n",
    "    ctx_h, ctx_w, _ = CONTEXT_SHAPE\n",
    "    fov_h, fov_w, _ = FOVEA_SHAPE\n",
    "    def _loader(features, label):\n",
    "        out_feats = {}\n",
    "        if \"context_input\" in features:\n",
    "            ctx = tf.io.read_file(features[\"context_input\"])\n",
    "            ctx = tf.io.decode_png(ctx, channels=1)\n",
    "            ctx = tf.image.convert_image_dtype(ctx, tf.float32)\n",
    "            ctx = tf.image.resize(ctx, [ctx_h, ctx_w])\n",
    "            ctx = tf.ensure_shape(ctx, CONTEXT_SHAPE)\n",
    "            out_feats[\"context_input\"] = ctx\n",
    "        if \"fovea_input\" in features:\n",
    "            fov = tf.io.read_file(features[\"fovea_input\"])\n",
    "            fov = tf.io.decode_png(fov, channels=1)\n",
    "            fov = tf.image.convert_image_dtype(fov, tf.float32)\n",
    "            fov = tf.image.resize(fov, [fov_h, fov_w])\n",
    "            fov = tf.ensure_shape(fov, FOVEA_SHAPE)\n",
    "            out_feats[\"fovea_input\"] = fov\n",
    "        return out_feats, label\n",
    "    ds = ds.map(_loader, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    if CACHE_TO_DISK and cache_file is not None:\n",
    "        os.makedirs(os.path.dirname(cache_file), exist_ok=True)\n",
    "        ds = ds.cache(cache_file)\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    if prefetch_to_device:\n",
    "        try:\n",
    "            if hasattr(tf.data, \"experimental\") and hasattr(tf.data.experimental, \"prefetch_to_device\"):\n",
    "                ds = ds.apply(tf.data.experimental.prefetch_to_device(\"/GPU:0\"))\n",
    "            elif hasattr(tf.data, \"experimental\") and hasattr(tf.data.experimental, \"copy_to_device\"):\n",
    "                ds = ds.apply(tf.data.experimental.copy_to_device(\"/GPU:0\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 - Tee logger to mirror stdout to file\n",
    "class Tee(object):\n",
    "    def __init__(self, filename, mode=\"a\"):\n",
    "        self.file = open(filename, mode, encoding=\"utf-8\")\n",
    "        self.stdout = sys.stdout\n",
    "    def write(self, data):\n",
    "        self.file.write(data); self.file.flush()\n",
    "        self.stdout.write(data); self.stdout.flush()\n",
    "    def flush(self):\n",
    "        self.file.flush(); self.stdout.flush()\n",
    "\n",
    "tee = Tee(os.path.join(OUTPUT_DIR, \"training_log.txt\"), \"a\")\n",
    "sys.stdout = tee\n",
    "sys.stderr = tee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8 - Load dataset paths and prepare KFold inputs\n",
    "print(\"# -------------------------------------------------------\")\n",
    "print(\"# Loading train, valid, test sets\")\n",
    "print(\"# Mode:\", \"Both streams\" if (USE_CONTEXT and USE_FOVEA) else (\"Context only\" if USE_CONTEXT else \"Fovea only\"))\n",
    "print(\"# -------------------------------------------------------\")\n",
    "print(\"# Using tf.data lazy pipeline (paths only, no big NumPy arrays)\")\n",
    "\n",
    "features_train = {}\n",
    "labels_train = None\n",
    "\n",
    "if USE_CONTEXT:\n",
    "    ctx_train_paths, y_train_ctx, train_fns_ctx = list_images_for_stream('train', context_res, CLASS_NAMES)\n",
    "    features_train[\"context_input\"] = ctx_train_paths\n",
    "    labels_train = y_train_ctx\n",
    "\n",
    "if USE_FOVEA:\n",
    "    fov_train_paths, y_train_fov, train_fns_fov = list_images_for_stream('train', f\"centerCrop_{fovea_res}\", CLASS_NAMES)\n",
    "    features_train[\"fovea_input\"] = fov_train_paths\n",
    "    labels_train = y_train_fov if labels_train is None else labels_train\n",
    "    if USE_CONTEXT:\n",
    "        for i, (a, b) in enumerate(zip(train_fns_ctx, train_fns_fov)):\n",
    "            if a != b:\n",
    "                print(f\"WARNING(train): filename mismatch at {i}: {a} vs {b}\")\n",
    "                break\n",
    "\n",
    "features_valid = {}\n",
    "if USE_CONTEXT:\n",
    "    ctx_valid_paths, y_valid_ctx, valid_fns_ctx = list_images_for_stream('valid', context_res, CLASS_NAMES)\n",
    "    features_valid[\"context_input\"] = ctx_valid_paths\n",
    "    y_valid_p = y_valid_ctx\n",
    "if USE_FOVEA:\n",
    "    fov_valid_paths, y_valid_fov, valid_fns_fov = list_images_for_stream('valid', f\"centerCrop_{fovea_res}\", CLASS_NAMES)\n",
    "    features_valid[\"fovea_input\"] = fov_valid_paths\n",
    "    y_valid_p = y_valid_fov\n",
    "    if USE_CONTEXT:\n",
    "        for i, (a, b) in enumerate(zip(valid_fns_ctx, valid_fns_fov)):\n",
    "            if a != b:\n",
    "                print(f\"WARNING(valid): filename mismatch at {i}: {a} vs {b}\")\n",
    "                break\n",
    "\n",
    "features_test = {}\n",
    "if USE_CONTEXT:\n",
    "    ctx_test_paths, y_test_ctx, test_fns_ctx = list_images_for_stream('test', context_res, CLASS_NAMES)\n",
    "    features_test[\"context_input\"] = ctx_test_paths\n",
    "    y_test_p = y_test_ctx\n",
    "if USE_FOVEA:\n",
    "    fov_test_paths, y_test_fov, test_fns_fov = list_images_for_stream('test', f\"centerCrop_{fovea_res}\", CLASS_NAMES)\n",
    "    features_test[\"fovea_input\"] = fov_test_paths\n",
    "    y_test_p = y_test_fov\n",
    "    if USE_CONTEXT:\n",
    "        for i, (a, b) in enumerate(zip(test_fns_ctx, test_fns_fov)):\n",
    "            if a != b:\n",
    "                print(f\"WARNING(test): filename mismatch at {i}: {a} vs {b}\")\n",
    "                break\n",
    "\n",
    "X_train_val_features: Dict[str, List[str]] = {}\n",
    "for k in features_train.keys():\n",
    "    X_train_val_features[k] = features_train[k] + features_valid.get(k, []) + features_test.get(k, [])\n",
    "y_train_val_labels = np.concatenate([labels_train, y_valid_p, y_test_p], axis=0)\n",
    "\n",
    "print(\"Full training set (paths only) prepared:\")\n",
    "for k, v in X_train_val_features.items():\n",
    "    print(f\"  #{k} paths:\", len(v))\n",
    "print(\"  #labels:   \", len(y_train_val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 - Set up KFold and training loop with checkpoints and plots\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_accuracies, fold_precisions, fold_recalls, fold_f1s = [], [], [], []\n",
    "csv_logger = CSVLogger(LOG_PATH, append=True)\n",
    "fold_classwise_reports = []\n",
    "y_for_kf = y_train_val_labels\n",
    "\n",
    "for fold_index, (train_idx, val_idx) in enumerate(kf.split(np.zeros_like(y_for_kf), y_for_kf), start=1):\n",
    "    print(f\"\\n=== Fold {fold_index} ===\")\n",
    "    fold_metrics_path = os.path.join(PLOTS_DIR, f\"fold_{fold_index}_metrics.json\")\n",
    "    if os.path.exists(fold_metrics_path):\n",
    "        with open(fold_metrics_path, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        print(f\"[Fold {fold_index}] Training already completed. Resuming from saved metrics.\")\n",
    "        print(f\"Fold {fold_index} - Validation Loss: {metrics['val_loss']:.4f}, Validation Accuracy: {metrics['val_acc']:.4f}\")\n",
    "        print(f\"Fold {fold_index} - Weighted Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, F1: {metrics['f1']:.4f}\")\n",
    "        fold_accuracies.append(metrics['val_acc'])\n",
    "        fold_precisions.append(metrics['precision'])\n",
    "        fold_recalls.append(metrics['recall'])\n",
    "        fold_f1s.append(metrics['f1'])\n",
    "        fold_classwise_reports.append(metrics.get(\"class_report\", {}))\n",
    "        continue\n",
    "\n",
    "    def slice_by_idx(lst, idxs): return [lst[i] for i in idxs]\n",
    "\n",
    "    features_train_fold: Dict[str, List[str]] = {}\n",
    "    features_val_fold:   Dict[str, List[str]] = {}\n",
    "    for k, v in X_train_val_features.items():\n",
    "        features_train_fold[k] = slice_by_idx(v, train_idx)\n",
    "        features_val_fold[k]   = slice_by_idx(v, val_idx)\n",
    "\n",
    "    y_train_fold = y_for_kf[train_idx]\n",
    "    y_val_fold   = y_for_kf[val_idx]\n",
    "\n",
    "    cache_train     = os.path.join(PIPE_CACHE_DIR, f\"fold{fold_index}_train.cache\") if CACHE_TO_DISK else None\n",
    "    cache_val_train = os.path.join(PIPE_CACHE_DIR, f\"fold{fold_index}_val_train.cache\") if CACHE_TO_DISK else None\n",
    "    cache_val_eval  = os.path.join(PIPE_CACHE_DIR, f\"fold{fold_index}_val_eval.cache\") if CACHE_TO_DISK else None\n",
    "\n",
    "    ds_train     = make_tf_dataset(features_train_fold, y_train_fold,\n",
    "                                    batch_size=BATCH_SIZE, shuffle=True,  drop_remainder=True,\n",
    "                                    cache_file=cache_train)\n",
    "    ds_val_train = make_tf_dataset(features_val_fold,   y_val_fold,\n",
    "                                    batch_size=BATCH_SIZE, shuffle=False, drop_remainder=True,\n",
    "                                    cache_file=cache_val_train)\n",
    "    ds_val_eval  = make_tf_dataset(features_val_fold,   y_val_fold,\n",
    "                                    batch_size=BATCH_SIZE, shuffle=False, drop_remainder=False,\n",
    "                                    cache_file=cache_val_eval)\n",
    "    \n",
    "    model = build_model(USE_CONTEXT, USE_FOVEA, CONTEXT_SHAPE, FOVEA_SHAPE, NUM_CLASSES)\n",
    "    opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[\"accuracy\"],\n",
    "        jit_compile=False\n",
    "    )\n",
    "\n",
    "    fold_best_checkpoint_path = os.path.join(CHECKPOINTS_DIR, f\"fold_{fold_index}_best_model.keras\")\n",
    "    fold_backup_dir = os.path.join(CHECKPOINTS_DIR, f\"fold_{fold_index}_backup\")\n",
    "    if os.path.exists(fold_backup_dir) and os.listdir(fold_backup_dir):\n",
    "        print(f\"[Fold {fold_index}] Found an existing backup. Training will resume from the last epoch.\")\n",
    "    else:\n",
    "        print(f\"[Fold {fold_index}] No existing backup. Training will start from scratch.\")\n",
    "    os.makedirs(fold_backup_dir, exist_ok=True)\n",
    "\n",
    "    best_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=fold_best_checkpoint_path, monitor='val_loss',\n",
    "        save_best_only=True, mode='min', verbose=1\n",
    "    )\n",
    "    backup_and_restore_callback = BackupAndRestore(backup_dir=fold_backup_dir)\n",
    "\n",
    "    class PauseEveryN(tf.keras.callbacks.Callback):\n",
    "        def __init__(self, n=100, seconds=300):\n",
    "            super().__init__(); self.n = n; self.seconds = seconds\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            if (epoch + 1) % self.n == 0:\n",
    "                print(f\"\\n[PauseEveryN] Sleeping {self.seconds} seconds after epoch {epoch+1} ...\")\n",
    "                time.sleep(self.seconds)\n",
    "                \n",
    "    pause_cb = PauseEveryN(n=PauseCounter, seconds=120)\n",
    "\n",
    "    history = model.fit(\n",
    "        x=ds_train,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=ds_val_train,\n",
    "        verbose=2,\n",
    "        callbacks=[\n",
    "            best_checkpoint_callback,\n",
    "            csv_logger,\n",
    "            backup_and_restore_callback,\n",
    "            pause_cb\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.load_weights(fold_best_checkpoint_path)\n",
    "    val_loss, val_acc = model.evaluate(ds_val_eval, verbose=0)\n",
    "    print(f\"Fold {fold_index} - Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    y_val_pred_probs = model.predict(ds_val_eval, verbose=0)\n",
    "    y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
    "\n",
    "    precision = precision_score(y_val_fold, y_val_pred, average=\"weighted\", zero_division=0)\n",
    "    recall    = recall_score(y_val_fold, y_val_pred, average=\"weighted\", zero_division=0)\n",
    "    f1        = f1_score(y_val_fold, y_val_pred, average=\"weighted\", zero_division=0)\n",
    "    print(f\"Fold {fold_index} - Weighted Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    fold_accuracies.append(val_acc); fold_precisions.append(precision)\n",
    "    fold_recalls.append(recall);     fold_f1s.append(f1)\n",
    "\n",
    "    test_data_npz_path = os.path.join(TEST_DATA_DIR, f\"fold_{fold_index}_test_data.npz\")\n",
    "    npz_kwargs = {\"y\": y_val_fold}\n",
    "    if USE_CONTEXT:\n",
    "        npz_kwargs[\"X_context_paths\"] = np.array(features_val_fold[\"context_input\"], dtype=object)\n",
    "    if USE_FOVEA:\n",
    "        npz_kwargs[\"X_fovea_paths\"]   = np.array(features_val_fold[\"fovea_input\"], dtype=object)\n",
    "    np.savez_compressed(test_data_npz_path, **npz_kwargs)\n",
    "    print(f\"[Fold {fold_index}] Test data saved to {test_data_npz_path}\")\n",
    "\n",
    "    cm = confusion_matrix(y_val_fold, y_val_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=CLASS_NAMES, columns=CLASS_NAMES)\n",
    "    cm_csv_path  = os.path.join(PLOTS_DIR, f\"fold_{fold_index}_confusion_matrix.csv\")\n",
    "    cm_plot_path = os.path.join(PLOTS_DIR, f\"fold_{fold_index}_confusion_matrix.png\")\n",
    "    cm_df.to_csv(cm_csv_path, index=True)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Fold {fold_index} - Confusion Matrix\")\n",
    "    plt.ylabel('Predicted Label'); plt.xlabel('True Label')\n",
    "    plt.savefig(cm_plot_path); plt.close()\n",
    "\n",
    "    class_report_dict = classification_report(\n",
    "        y_val_fold, y_val_pred, target_names=CLASS_NAMES, digits=4, output_dict=True, zero_division=0\n",
    "    )\n",
    "    per_class_dict = {cls: {\n",
    "        \"precision\": class_report_dict[cls][\"precision\"] * 100.0,\n",
    "        \"recall\":    class_report_dict[cls][\"recall\"]    * 100.0,\n",
    "        \"f1\":        class_report_dict[cls][\"f1-score\"]  * 100.0\n",
    "    } for cls in CLASS_NAMES}\n",
    "    fold_classwise_reports.append(per_class_dict)\n",
    "\n",
    "    shape_tag = []\n",
    "    if USE_CONTEXT: shape_tag.append(f\"ctx{CONTEXT_SHAPE[0]}x{CONTEXT_SHAPE[1]}\")\n",
    "    if USE_FOVEA:   shape_tag.append(f\"fov{FOVEA_SHAPE[0]}x{FOVEA_SHAPE[1]}\")\n",
    "    shape_tag = \"_\".join(shape_tag) if shape_tag else \"unknown\"\n",
    "    history_pickle_path = os.path.join(PLOTS_DIR, f\"history_{mode_tag}_{shape_tag}_fold{fold_index}.pkl\")\n",
    "    history_json_path   = os.path.join(PLOTS_DIR, f\"history_{mode_tag}_{shape_tag}_fold{fold_index}.json\")\n",
    "    with open(history_pickle_path, 'wb') as f: pickle.dump(history.history, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(history_json_path, 'w') as f: json.dump(history.history, f)\n",
    "\n",
    "    plt.figure(figsize=(8, 6)); plt.plot(history.history['accuracy'], label='Train Accuracy'); plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.title(f'Fold {fold_index} Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, f\"fold_{fold_index}_accuracy.png\")); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 6)); plt.plot(history.history['loss'], label='Train Loss'); plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(f'Fold {fold_index} Loss'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.grid(True)\n",
    "    plt.savefig(os.path.join(PLOTS_DIR, f\"fold_{fold_index}_loss.png\")); plt.close()\n",
    "\n",
    "    fold_metrics = {\"val_loss\": val_loss, \"val_acc\": val_acc, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"class_report\": per_class_dict}\n",
    "    with open(fold_metrics_path, 'w') as f: json.dump(fold_metrics, f)\n",
    "\n",
    "    try:\n",
    "        del ds_train, ds_val_train, ds_val_eval, features_train_fold, features_val_fold\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        del y_train_fold, y_val_fold, y_val_pred_probs, y_val_pred, cm, cm_df, class_report_dict, per_class_dict\n",
    "    except Exception:\n",
    "        pass\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 - Aggregate cross-validation metrics and save per-class averages\n",
    "mean_acc = np.mean(fold_accuracies)\n",
    "mean_pre = np.mean(fold_precisions)\n",
    "mean_rec = np.mean(fold_recalls)\n",
    "mean_f1  = np.mean(fold_f1s)\n",
    "\n",
    "print(\"\\n=== 5-Fold Cross-Validation Results (Weighted Average) ===\")\n",
    "print(f\"Accuracy:  {mean_acc:.4f}\")\n",
    "print(f\"Precision: {mean_pre:.4f}\")\n",
    "print(f\"Recall:    {mean_rec:.4f}\")\n",
    "print(f\"F1-score:  {mean_f1:.4f}\")\n",
    "\n",
    "def average_class_metrics(list_of_dicts, class_names):\n",
    "    avg_dict = {}\n",
    "    for cls_name in class_names:\n",
    "        precs = [d[cls_name][\"precision\"] for d in list_of_dicts]\n",
    "        recs  = [d[cls_name][\"recall\"]   for d in list_of_dicts]\n",
    "        f1s   = [d[cls_name][\"f1\"]       for d in list_of_dicts]\n",
    "        avg_dict[cls_name] = {\n",
    "            \"precision\": np.mean(precs),\n",
    "            \"recall\":    np.mean(recs),\n",
    "            \"f1\":        np.mean(f1s)\n",
    "        }\n",
    "    return avg_dict\n",
    "\n",
    "avg_classwise = average_class_metrics(fold_classwise_reports, CLASS_NAMES)\n",
    "\n",
    "print(\"\\n=== Table 1 (Per-Class Averages over 5-Fold) ===\")\n",
    "for cls_name in CLASS_NAMES:\n",
    "    metrics = avg_classwise[cls_name]\n",
    "    print(f\"{cls_name} => Precision: {metrics['precision']:.2f}%, \"\n",
    "          f\"Recall: {metrics['recall']:.2f}%, F1: {metrics['f1']:.2f}%\")\n",
    "\n",
    "output_file = os.path.join(PLOTS_DIR, \"per_class_metrics.txt\")\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"\\n=== Table 1 (Per-Class Averages over 5-Fold) ===\\n\")\n",
    "    for cls_name in CLASS_NAMES:\n",
    "        metrics = avg_classwise[cls_name]\n",
    "        line = (f\"{cls_name} => Precision: {metrics['precision']:.2f}%, \"\n",
    "                f\"Recall: {metrics['recall']:.2f}%, F1: {metrics['f1']:.2f}%\\n\")\n",
    "        f.write(line)\n",
    "print(f\"Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11 - TFLite conversion and C array export for all folds\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "CHECKPOINTS_DIR = os.path.join(OUTPUT_DIR, \"checkpoints\")\n",
    "TFLITE_DIR = os.path.join(OUTPUT_DIR, \"quantized_models_ptq\")\n",
    "C_ARRAY_DIR = os.path.join(OUTPUT_DIR, \"c_arrays_ptq\")\n",
    "\n",
    "os.makedirs(TFLITE_DIR, exist_ok=True)\n",
    "os.makedirs(C_ARRAY_DIR, exist_ok=True)\n",
    "\n",
    "def quantize_and_convert_to_c(fold_index):\n",
    "    keras_model_path = os.path.join(CHECKPOINTS_DIR, f\"fold_{fold_index}_best_model.keras\")\n",
    "    tflite_model_path = os.path.join(TFLITE_DIR, f\"fold{fold_index}.tflite\")\n",
    "    tmp_c_path = os.path.join(C_ARRAY_DIR, f\"_tmp_fold{fold_index}.h\")\n",
    "    final_c_path = os.path.join(C_ARRAY_DIR, f\"fold{fold_index}_model_data.h\")\n",
    "    var_name = f\"fold{fold_index}_model\"\n",
    "    model = tf.keras.models.load_model(keras_model_path)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    with open(tflite_model_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"✅ TFLite model saved: {tflite_model_path}\")\n",
    "    with open(tmp_c_path, \"w\") as out:\n",
    "        subprocess.run([\"xxd\", \"-i\", tflite_model_path], stdout=out)\n",
    "    with open(tmp_c_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    content = re.sub(r'unsigned char\\s+\\w+\\s*\\[\\]', f'unsigned char {var_name}[]', content)\n",
    "    content = re.sub(r'unsigned int\\s+\\w+_len', f'unsigned int {var_name}_len', content)\n",
    "    guard_name = f\"FOLD{fold_index}_MODEL_DATA_H\"\n",
    "    header_guard = f\"#ifndef {guard_name}\\n#define {guard_name}\\n\\n\"\n",
    "    footer_guard = \"\\n#endif\\n\"\n",
    "    with open(final_c_path, \"w\") as f:\n",
    "        f.write(header_guard)\n",
    "        f.write(content)\n",
    "        f.write(footer_guard)\n",
    "    os.remove(tmp_c_path)\n",
    "    print(f\"✅ C array saved with variable: {var_name} in {final_c_path}\")\n",
    "\n",
    "for fold in range(1, 6):\n",
    "    quantize_and_convert_to_c(fold)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
